.. _preprocessing:

*************
Preprocessing
*************

Executing Marius over a certain dataset requires the dataset to be preprocessed into the specific format recognized by Marius.
Marius provides the ``marius_preprocess`` as a handy tool for users to download
and convert 21 popular datasets into Marius trainable version. Marius comes with these 21
datasets included with out of the box.
Users can obtain the trainable versions of these datasets by calling ``marius_preprocess`` directly from command line.


Use ``marius_preprocess`` for Datasets Supported By Marius
----------------------------------------------------------

Users can download and convert 21 popular datasets to trainable versions 
with the command ``marius_preprocess <dataset> <output_directory>`` in terminal. 
The ``<dataset>`` is the alias for dataset and can be found in the :ref:`datasets` table below.
The ``output_directory`` is the directory where all trainable data will be stored.
``marius_preprocess`` will create this directory if the directory does not exist.
It is also the value should be set for ``path.base_directory`` in Marius configuration file.
In addition to these 2 requried command line arguments, ``marius_preprocess`` also offers users 
other options including ``--help``, ``--num_partitions``, ``--overwrite``, ``--generate_config``
and specifying certain configuration for Marius.

<dataset>
^^^^^^^^^
The ``<dataset>`` is a **requried** option for ``marius_preprocess``. 
It is the alias for the datasets will be preprocessed. These alias can be found in 
the :ref:`datasets` table.

<output_directory>
^^^^^^^^^^^^^^^^^^
The ``<output_directory>`` is a **required** option for ``marius_preprocess``. 
It is the directory where all the files generated by ``marius_preprocess`` wil be stored.
``marius_preprocess`` will create this file if it does not exist.
In addition to raw dataset downloaded, ``output_dir`` will also have the
output files from ``marius_preprocess`` shown in the following table.

==================  ============
File                Description
------------------  ------------
train_edges.pt      Contains edges for training set;

                    Should be set for ``path.train_edges`` in Marius configuration file
valid_edges.pt      Contains edges for validation set; 

                    Should be set for ``path.train_edges`` in Marius configuration file
test_edges.pt       Contains edges for test set; 

                    Should be set for ``path.train_edges`` in Marius configuration file
node_mapping.txt    Contains 2 columns; 
                    The first column is all the original node IDs from raw data, the second column is all the remapped node IDs
rel_mapping.txt     Contains 2 columns; 

                    The first column is all the original relation IDs from raw data, the second column is all the remapped relation IDs
==================  ============

Each edge in ``train_edges.pt``, ``valid_edges.pt``, and ``test_edges.pt`` is stored
in the format of ``source relation destination`` on 1 row.
The 2 Node IDs and relation IDs are stored as 3 4-byte integers (or 8-byte integers
if the storage data type is set to int64). 
The source, relation and destinatio of edge ``i`` can be retrieved from 
``train_edges.pt``, ``valid_edges.pt``, and ``test_edges.pt``
files by reading 3 4-byte integers (or 8-byte integers if using int64 data type for storage)
at the offset in the file ``i * 3 * 4`` (or ``i * 3 * 8`` when using int64).


\-\-num_partitions
^^^^^^^^^^^^^^^^^^
The ``--num_partitions <num_partitions>`` is an optional option for ``marius_preprocess``.
If this option is specified, the nodes of the input graph will be partitioned into ``<num_partitions>``.

\-\-overwrite
^^^^^^^^^^^^^
The ``--overwrite`` is an **optional** option for ``marius_preprocess``. If this option is set, then
the ``<output_directory>`` will be overwritten. Otherwise, ``marius_preprocess`` will treat the files
in ``<output_directory>`` with the same file names as the latest files for current run. When switching
from one dataset to another one, the converted data files of the previous dataset in same ``<output_directory>``
may be treated as the already-preprocessed data files for the current dataset if this option is not set.

\-\-generate_config <device>, \-gc <device>
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
The ``--generate_config <device>, -gc <device>`` is an **optional** option for ``marius_preprocess``.
If this option is set, ``marius_preprocess`` will generate a Marius configuration
file in the ``<output_directory>`` with all configuration parameters set to the recommended defaults if not 
explicitly defined.
The generated Marius configuration is for single-GPU setting by default if ``<device>`` is not set.
If other device, such as ``CPU`` or ``multi-GPU``, is required, users can just append the option after
``--generate_config``, e.g. ``--generate_config CPU``.
For example, the following example will set ``general.device=CPU`` in the Marius 
configuration file generated for WordNet18 (``wn18_cpu.ini``).

::

    marius_perprocess wn18 ./output_dir --generate_config CPU

\-\-<section>.<key>=<value>
^^^^^^^^^^^^^^^^^^^^^^^^^^^
The ``--<section>.<key>=<value>`` is an **optional** option for ``marius_preprocess``.
When ``--generate_config <device>`` is set, ``--<section>.<key>=<value>`` can be used
to change the value of certain option in the Marius configuration file generated.
For example, the following example will set ``model.embedding_sze=256`` and ``training.num_epochs=100``
in the Marius configuration file generated for WordNet18 (``wn18_gpu.ini``).

::

    marius_preprocess wn18 ./output_dir --generate_config --model.embedding_sze=256 --training.num_epochs=100

\-\-help, \-h
^^^^^^^^^^^^^
The ``--help, -h`` is an **optional** option for ``marius_preprocess``. 
It prints out the help messages in terminal.

::

    user@ubuntu: marius_preprocess --help
    usage: preprocessor [-h] [--num_partitions num_partitions] [--overwrite] [--generate_config [generate_config]] dataset output_directory

    Preprocess Datasets

    positional arguments:
    dataset               Dataset to preprocess
    output_directory      Directory to put graph data

    optional arguments:
    -h, --help            show this help message and exit
    --num_partitions num_partitions
                            Number of partitions to split the edges into
    --overwrite           Overwrites the output_directory if this is set. Otherwise, files with same the names will be treated as the data for current dataset.
    --generate_config [generate_config], -gc [generate_config]
                            Generates a single-GPU training configuration file by default.
                            Valid options (default to GPU): [GPU, CPU, multi-GPU]

    Specify certain config (optional): [--<section>.<key>=<value>]

.. _datasets:

Datasets
--------
The following table contains the information of the 21 datasets Marius comes included out of the box.

==================  ==========  ======================  ==========
Dataset Name        Entities    Relations (edge-types)  Edges  
------------------  ----------  ----------------------  ----------
live_journal        4847571     1                       68993773
fb15k               14951       1345                    592213
fb15k_237           114541      237                     310116
wn18                40943       18                      151442
wn18rr              40943       11                      93003
codex_s             2034        42                      36543
codex_m             17050       51                      206205
codex_l             77951       69                      612437
drkg                97238       107                     5874261
hetionet            45160       25                      2250198
freebase86m         86054151    14824                   338586276
kinships            24          12                      112
ogbl_ppa            576289      1                       30326273
ogbl_ddi            4267        1                       1334889
ogbl_collab         235868      1                       1285465
ogbl_biokg          45085       51                      5088434
ogbn_arxiv          169341      1                       1166243
ogbn_proteins       132534      1                       39561254
ogbn_products       2400608     1                       61859140
openbiolink_hq      184635      28                      4563405
openbiolink_lq      486942      32                      27320889
==================  ==========  ======================  ==========

Example of Using ``marius_preprocess`` Over WordNet18
------------------------------------------------------

The following example uses ``marius_preprocess`` for downloading and 
converting the dataset WordNet18 to Marius trainable version from command line.
``wn18`` is the alias for WordNet18 in ``marius_perprocess``. The aliaes for
all the datasets supported by Marius can be found in the :ref:`datasets` table below.
``./output_dir`` is the directory where all the converted data will be stored.

In addition to generating a Marius trainable version over WordNet18, this command also
asks ``marius_preprocess`` to generate a Marius configuration file for CPU over WordNet18.
In this Marius configuration file, the hyper-parameter ``model.decoder=TransE`` is set.

Apart from some progress information, the terminal output
of ``marius_preprocess`` also gives some statistics of the 
database being preprocessed. ``Number of instance per file:[141442, 5000, 5000]``
gives the number of edges in the training, validation and testing sets respectively.
``Number of nodes: 40943`` shows the total number of nodes in the dataset. 
``Number of edges: 151442`` reveals the total number of edges in the dataset.
``Number of relations: 18`` is the total number of relations appear in the dataset.
These dataset statistics not only gives the users an overview to the structure of 
the dataset but also make it easy for users to set dataset information in 
Marius configuration file.

The terminal output also shows ``Detected delimiter: ~  ~`` and ``Delimiter: ~  ~``.
These 2 lines reminds the users what delimiter between entities in the same line has been used in the preprocessing.
In this case ``\t`` is used in the raw data files to seperate 2 entities in the same line.

::

    user@ubuntu: marius_preprocess wn18 ./output_dir --overwrite --generate_config CPU --model.decoder=TransE
    Downloading fetch.phpmedia=en:wordnet-mlj12.tar.gz to output_dir/fetch.phpmedia=en:wordnet-mlj12.tar.gz
    Extracting
    Extraction completed
    Detected delimiter: ~   ~
    Reading in output_dir/wordnet-mlj12-train.txt   1/3
    Reading in output_dir/wordnet-mlj12-valid.txt   2/3
    Reading in output_dir/wordnet-mlj12-test.txt   3/3
    Number of instance per file: [141442, 5000, 5000]
    Number of nodes: 40943
    Number of edges: 151442
    Number of relations: 18
    Delimiter: ~    ~